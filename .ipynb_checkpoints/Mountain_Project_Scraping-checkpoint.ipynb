{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mountain Project Scraping",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mLZuWXK5JvQl0PfI9MznD_nYvwXeF6Le",
      "authorship_tag": "ABX9TyO+c4uRzztZJAU9f1k/3fE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColeDCrawford/mp-scrape/blob/master/Mountain_Project_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hh_QQf-Jcce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "\n",
        "idPattern = re.compile(\"^[0-9]{1,10}$\")\n",
        "uniqueRouteIds = set()\n",
        "route_location_ids = []\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FUh2NOzTNnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getId(url):\n",
        "  values = url.split(\"/\")\n",
        "  id = values[4]\n",
        "  if idPattern.match(id) is not None:\n",
        "    return int(id)\n",
        "  else:\n",
        "    print(f\"Error: id {id} url {url}\")\n",
        "    return False\n",
        "\n",
        "def getRoutes(soup):\n",
        "  # returns tuple of hrefs, ids\n",
        "  links = soup.select(\"#left-nav-route-table a\")\n",
        "  hrefs = []\n",
        "  ids = []\n",
        "  for link in links:\n",
        "    href = link.get(\"href\")\n",
        "    ids.append(getId(href))\n",
        "    hrefs.append(href)\n",
        "  return hrefs, ids\n",
        "\n",
        "def getStates(soup):\n",
        "    groups = soup.find_all(\"div\", class_=\"mb-half\")\n",
        "    states_dict = {}\n",
        "    for group in groups:\n",
        "        strong = group.find(\"strong\")\n",
        "        link = strong.find(\"a\")\n",
        "        url = link.get(\"href\")\n",
        "        id = getId(url)\n",
        "        states_dict[link.get(\"href\")] = {\n",
        "            \"url\": url,\n",
        "            \"title\": link.get_text(),\n",
        "            \"id\": id,\n",
        "            \"subareas\": [],\n",
        "            \"parent\": None,\n",
        "            \"routes\": False,\n",
        "            \"subAreaUrls\": [],\n",
        "            \"subAreaIds\": []\n",
        "        }\n",
        "    return states_dict  \n",
        "\n",
        "def getAreas(url):\n",
        "    page = requests.get(url)\n",
        "    soup = bs(page.content)\n",
        "    areas = []\n",
        "    ids = []\n",
        "\n",
        "    divs = soup.find_all(\"div\", class_=\"lef-nav-row\")\n",
        "    for div in divs:\n",
        "      link = div.find(\"a\")\n",
        "      href = link.get(\"href\")\n",
        "      areas.append(href)\n",
        "\n",
        "      id = getId(href)\n",
        "      ids.append(id)\n",
        "    return areas, ids\n",
        "\n",
        "def getSubAreas(url, level=0, parent=None, shouldGetRoutes=False):\n",
        "  # time.sleep(.5)\n",
        "  page = requests.get(url)\n",
        "  soup = bs(page.content)\n",
        "  title = soup.find(\"h1\").find(text=True, recursive=False)\n",
        "  title = title.strip()\n",
        "  id = getId(url)\n",
        "  print(title)\n",
        "\n",
        "  try:\n",
        "    header_list = soup.select(\".mp-sidebar h3\")\n",
        "    header = header_list[0]\n",
        "    if \"Routes in \" in header.get_text():\n",
        "      routeArea = {\n",
        "          \"url\": url,\n",
        "          \"title\": title,\n",
        "          \"level\": level,\n",
        "          \"parent\": parent,\n",
        "          \"id\": id,\n",
        "          \"routes\": True,\n",
        "      }\n",
        "      if shouldGetRoutes:\n",
        "        hrefs, ids = getRoutes(soup)\n",
        "        routeArea[\"routeIds\"] = ids\n",
        "        routeArea[\"routeLinks\"] = hrefs\n",
        "        uniqueRouteIds.update(ids)\n",
        "        joined = []\n",
        "        for routeId in ids:\n",
        "          route_location_ids.append((routeId, id))\n",
        "      subareas.append(routeArea)\n",
        "    elif \"Areas in \" in header.get_text():\n",
        "      ids = []\n",
        "      links = []\n",
        "      divs = soup.find_all(\"div\", class_=\"lef-nav-row\")\n",
        "      print(f\"Subareas: {len(divs)}\")\n",
        "\n",
        "      for div in divs:\n",
        "        link = div.find(\"a\").get(\"href\")\n",
        "        links.append(link)\n",
        "        ids.append(getId(link))\n",
        "      subareas.append({\n",
        "          \"url\": url,\n",
        "          \"title\": title,\n",
        "          \"level\": level,\n",
        "          \"parent\": parent,\n",
        "          \"id\": id,\n",
        "          \"routes\": False,\n",
        "          \"subAreaUrls\": links,\n",
        "          \"subAreaIds\": ids\n",
        "      })\n",
        "      level += 1\n",
        "      for link in links:\n",
        "        getSubAreas(link, level=level, parent=url, shouldGetRoutes=shouldGetRoutes)\n",
        "\n",
        "    else:\n",
        "      # area without subarea or routes\n",
        "      print(f\"area without routes or subareas - {header.get_text()}\")\n",
        "      subareas.append({\n",
        "          \"url\": url,\n",
        "          \"title\": title,\n",
        "          \"level\": level,\n",
        "          \"parent\": parent,\n",
        "          \"id\": id,\n",
        "          \"routes\": False\n",
        "      })\n",
        "  except IndexError:\n",
        "    print(f\"IndexError - {title}\")\n",
        "    subareas.append({\n",
        "      \"url\": url,\n",
        "      \"title\": title,\n",
        "      \"level\": level,\n",
        "      \"id\": id,\n",
        "      \"parent\": parent,\n",
        "      \"routes\": False\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW37DYvGLYrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "homepage = requests.get(\"https://www.mountainproject.com/\")\n",
        "soup = bs(homepage.content)\n",
        "\n",
        "states = getStates(soup)\n",
        "states_keys = ['https://www.mountainproject.com/area/106092653/iowa', 'https://www.mountainproject.com/area/107235316/kansas', 'https://www.mountainproject.com/area/105868674/kentucky', 'https://www.mountainproject.com/area/116720343/louisiana', 'https://www.mountainproject.com/area/105948977/maine', 'https://www.mountainproject.com/area/106029417/maryland', 'https://www.mountainproject.com/area/105908062/massachusetts', 'https://www.mountainproject.com/area/106113246/michigan', 'https://www.mountainproject.com/area/105812481/minnesota', 'https://www.mountainproject.com/area/108307056/mississippi', 'https://www.mountainproject.com/area/105899020/missouri', 'https://www.mountainproject.com/area/105907492/montana', 'https://www.mountainproject.com/area/116096758/nebraska', 'https://www.mountainproject.com/area/105708961/nevada', 'https://www.mountainproject.com/area/105872225/new-hampshire', 'https://www.mountainproject.com/area/106374428/new-jersey', 'https://www.mountainproject.com/area/105708964/new-mexico', 'https://www.mountainproject.com/area/105800424/new-york', 'https://www.mountainproject.com/area/105873282/north-carolina', 'https://www.mountainproject.com/area/106598130/north-dakota', 'https://www.mountainproject.com/area/105994953/ohio', 'https://www.mountainproject.com/area/105854466/oklahoma', 'https://www.mountainproject.com/area/105708965/oregon', 'https://www.mountainproject.com/area/105913279/pennsylvania', 'https://www.mountainproject.com/area/106842810/rhode-island', 'https://www.mountainproject.com/area/107638915/south-carolina', 'https://www.mountainproject.com/area/105708963/south-dakota', 'https://www.mountainproject.com/area/105887760/tennessee', 'https://www.mountainproject.com/area/105835804/texas', 'https://www.mountainproject.com/area/105708957/utah', 'https://www.mountainproject.com/area/105891603/vermont', 'https://www.mountainproject.com/area/105852400/virginia', 'https://www.mountainproject.com/area/105708966/washington', 'https://www.mountainproject.com/area/105855459/west-virginia', 'https://www.mountainproject.com/area/105708968/wisconsin', 'https://www.mountainproject.com/area/105708960/wyoming', 'https://www.mountainproject.com/area/105907743/international', 'https://www.mountainproject.com/area/105798164/in-progress']\n",
        "skip = ['https://www.mountainproject.com/area/105905173/alabama', 'https://www.mountainproject.com/area/105909311/alaska','https://www.mountainproject.com/area/105708962/arizona', 'https://www.mountainproject.com/area/105901027/arkansas', 'https://www.mountainproject.com/area/105708959/california', 'https://www.mountainproject.com/area/105708956/colorado', 'https://www.mountainproject.com/area/105806977/connecticut', 'https://www.mountainproject.com/area/106861605/delaware', 'https://www.mountainproject.com/area/111721391/florida', 'https://www.mountainproject.com/area/105897947/georgia', 'https://www.mountainproject.com/area/106316122/hawaii', 'https://www.mountainproject.com/area/105708958/idaho', 'https://www.mountainproject.com/area/105911816/illinois', 'https://www.mountainproject.com/area/112389571/indiana']\n",
        "for key in skip:\n",
        "  states.pop(key)\n",
        "print(states)\n",
        "last = skip[-1].split(\"/\")[-1]\n",
        "print(last)\n",
        "\n",
        "for key in states:\n",
        "  areas, ids = getAreas(key)\n",
        "  states[key]['subAreaIds'] = ids\n",
        "  states[key]['subAreaUrls'] = areas\n",
        "  subareas = []\n",
        "  print(f\"\\n\\n ------{key} ------\")\n",
        "  for area in areas:\n",
        "    getSubAreas(area, parent=key, shouldGetRoutes=True)\n",
        "  states[key]['subareas'] = subareas\n",
        "  print(f\"Subareas scraped in this state: {len(subareas)}\")\n",
        "  print(f\"Total route IDs scraped: {len(uniqueRouteIds)}\")\n",
        "\n",
        "  data = cleanDataForExport(states)\n",
        "  df_areas = pd.DataFrame(data)\n",
        "  # df_areas.to_csv(f\"/content/gdrive/'My Drive'/'Mountain Project Scrape'/areas.csv\", index=False)\n",
        "  df_areas.to_csv(f\"/content/gdrive/My Drive/Mountain Project Scrape/areas-after-{last}.csv\", index=False)\n",
        "\n",
        "  df_routes = pd.DataFrame(uniqueRouteIds)\n",
        "  df_routes.to_csv(f\"/content/gdrive/My Drive/Mountain Project Scrape/route_ids-after-{last}.csv\", index=False)\n",
        "\n",
        "  with open(f\"/content/gdrive/My Drive/Mountain Project Scrape/route_loc_ids-after-{last}.csv\", \"w\", newline='') as out:\n",
        "    csv_out = csv.writer(out)\n",
        "    csv_out.writerow(['routeId', 'locationId'])\n",
        "    for row in route_location_ids:\n",
        "      csv_out.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I52mvcnpMmCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanDataForExport(dirty):\n",
        "  areas = []\n",
        "  for key, value in dirty.items():\n",
        "    areas.append({\n",
        "        'parent': value['parent'],\n",
        "        'title': value['title'],\n",
        "        'url': value['url'],\n",
        "        'subAreaIds': value['subAreaIds'],\n",
        "        'subAreaUrls': value['subAreaUrls'],\n",
        "        'routes': value['routes'],\n",
        "        'id': value['id']\n",
        "    })\n",
        "    areas.extend(value['subareas'])\n",
        "  return areas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWiHqSoBaB3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Export Routes\n",
        "# df_routes = pd.DataFrame(uniqueRouteIds)\n",
        "# df_routes.to_csv('route_ids.csv', index=False)\n",
        "\n",
        "# # Export Areas\n",
        "# data = cleanDataForExport(states)\n",
        "# df_areas = pd.DataFrame(data)\n",
        "# df_areas.to_csv('areas.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh40IObSxcmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_routes = []\n",
        "\n",
        "import csv\n",
        "route_location_ids = {}\n",
        "with open(\"/content/gdrive/My Drive/Mountain Project Scrape/route_loc_ids.csv\") as read_obj:\n",
        "  csv_dict_reader = csv.DictReader(read_obj)\n",
        "  for row in csv_dict_reader:\n",
        "    route_location_ids[int(row['routeId'])] = int(row['locationId'])\n",
        "\n",
        "def get_routes(ids, pause=5):\n",
        "  time.sleep(pause)\n",
        "  str_ids = ','.join(str(x) for x in ids)\n",
        "  params = {\n",
        "      'key': apikey,\n",
        "      'routeIds': str_ids\n",
        "  }\n",
        "  r = requests.get('https://www.mountainproject.com/data/get-routes', params=params)\n",
        "  if(r.json()['success'] == 1):\n",
        "    routes = r.json()['routes']\n",
        "    # enhance with location ID\n",
        "    for route in routes:\n",
        "      locationId = route_location_ids[route['id']]\n",
        "      route['locationId'] = locationId\n",
        "    return routes\n",
        "  else:\n",
        "    print(\"Error\")\n",
        "    print(r.json())\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2JZ-_vAKbv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all routes\n",
        "routeIds = list(route_location_ids.keys())\n",
        "\n",
        "def divide_chunks(l, n): \n",
        "  for i in range(0, len(l), n):  \n",
        "    yield l[i:i + n]\n",
        "\n",
        "chunked = list(divide_chunks(routeIds, 200))\n",
        "i = 0\n",
        "for chunk in chunked:\n",
        "  routes = get_routes(chunk)\n",
        "  all_routes.extend(routes)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}