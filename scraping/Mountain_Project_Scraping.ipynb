{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ColeDCrawford/mp-scrape/blob/master/Mountain_Project_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Hh_QQf-Jcce"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "idPattern = re.compile(\"^[0-9]{1,10}$\")\n",
    "uniqueRouteIds = set()\n",
    "route_location_ids = []\n",
    "\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "import time\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FUh2NOzTNnI"
   },
   "outputs": [],
   "source": [
    "def getId(url):\n",
    "  values = url.split(\"/\")\n",
    "  id = values[4]\n",
    "  if idPattern.match(id) is not None:\n",
    "    return int(id)\n",
    "  else:\n",
    "    print(f\"Error: id {id} url {url}\")\n",
    "    return False\n",
    "\n",
    "def getRoutes(soup):\n",
    "  # returns tuple of hrefs, ids\n",
    "  links = soup.select(\"#left-nav-route-table a\")\n",
    "  hrefs = []\n",
    "  ids = []\n",
    "  for link in links:\n",
    "    href = link.get(\"href\")\n",
    "    ids.append(getId(href))\n",
    "    hrefs.append(href)\n",
    "  return hrefs, ids\n",
    "\n",
    "def getStates(soup):\n",
    "    groups = soup.find_all(\"div\", class_=\"mb-half\")\n",
    "    states_dict = {}\n",
    "    for group in groups:\n",
    "        strong = group.find(\"strong\")\n",
    "        link = strong.find(\"a\")\n",
    "        url = link.get(\"href\")\n",
    "        id = getId(url)\n",
    "        states_dict[link.get(\"href\")] = {\n",
    "            \"url\": url,\n",
    "            \"title\": link.get_text(),\n",
    "            \"id\": id,\n",
    "            \"subareas\": [],\n",
    "            \"parent\": None,\n",
    "            \"routes\": False,\n",
    "            \"subAreaUrls\": [],\n",
    "            \"subAreaIds\": []\n",
    "        }\n",
    "    return states_dict  \n",
    "\n",
    "def getAreas(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    areas = []\n",
    "    ids = []\n",
    "\n",
    "    divs = soup.find_all(\"div\", class_=\"lef-nav-row\")\n",
    "    for div in divs:\n",
    "      link = div.find(\"a\")\n",
    "      href = link.get(\"href\")\n",
    "      areas.append(href)\n",
    "\n",
    "      id = getId(href)\n",
    "      ids.append(id)\n",
    "    return areas, ids\n",
    "\n",
    "def getSubAreas(url, level=0, parent=None, shouldGetRoutes=False):\n",
    "  # time.sleep(.5)\n",
    "  page = requests.get(url)\n",
    "  soup = bs(page.content)\n",
    "  title = soup.find(\"h1\").find(text=True, recursive=False)\n",
    "  title = title.strip()\n",
    "  id = getId(url)\n",
    "  print(title)\n",
    "\n",
    "  try:\n",
    "    header_list = soup.select(\".mp-sidebar h3\")\n",
    "    header = header_list[0]\n",
    "    if \"Routes in \" in header.get_text():\n",
    "      routeArea = {\n",
    "          \"url\": url,\n",
    "          \"title\": title,\n",
    "          \"level\": level,\n",
    "          \"parent\": parent,\n",
    "          \"id\": id,\n",
    "          \"routes\": True,\n",
    "      }\n",
    "      if shouldGetRoutes:\n",
    "        hrefs, ids = getRoutes(soup)\n",
    "        routeArea[\"routeIds\"] = ids\n",
    "        routeArea[\"routeLinks\"] = hrefs\n",
    "        uniqueRouteIds.update(ids)\n",
    "        joined = []\n",
    "        for routeId in ids:\n",
    "          route_location_ids.append((routeId, id))\n",
    "      subareas.append(routeArea)\n",
    "    elif \"Areas in \" in header.get_text():\n",
    "      ids = []\n",
    "      links = []\n",
    "      divs = soup.find_all(\"div\", class_=\"lef-nav-row\")\n",
    "      print(f\"Subareas: {len(divs)}\")\n",
    "\n",
    "      for div in divs:\n",
    "        link = div.find(\"a\").get(\"href\")\n",
    "        links.append(link)\n",
    "        ids.append(getId(link))\n",
    "      subareas.append({\n",
    "          \"url\": url,\n",
    "          \"title\": title,\n",
    "          \"level\": level,\n",
    "          \"parent\": parent,\n",
    "          \"id\": id,\n",
    "          \"routes\": False,\n",
    "          \"subAreaUrls\": links,\n",
    "          \"subAreaIds\": ids\n",
    "      })\n",
    "      level += 1\n",
    "      for link in links:\n",
    "        getSubAreas(link, level=level, parent=url, shouldGetRoutes=shouldGetRoutes)\n",
    "\n",
    "    else:\n",
    "      # area without subarea or routes\n",
    "      print(f\"area without routes or subareas - {header.get_text()}\")\n",
    "      subareas.append({\n",
    "          \"url\": url,\n",
    "          \"title\": title,\n",
    "          \"level\": level,\n",
    "          \"parent\": parent,\n",
    "          \"id\": id,\n",
    "          \"routes\": False\n",
    "      })\n",
    "  except IndexError:\n",
    "    print(f\"IndexError - {title}\")\n",
    "    subareas.append({\n",
    "      \"url\": url,\n",
    "      \"title\": title,\n",
    "      \"level\": level,\n",
    "      \"id\": id,\n",
    "      \"parent\": parent,\n",
    "      \"routes\": False\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XW37DYvGLYrU"
   },
   "outputs": [],
   "source": [
    "homepage = requests.get(\"https://www.mountainproject.com/\")\n",
    "soup = bs(homepage.content)\n",
    "\n",
    "states = getStates(soup)\n",
    "states_keys = ['https://www.mountainproject.com/area/106092653/iowa', 'https://www.mountainproject.com/area/107235316/kansas', 'https://www.mountainproject.com/area/105868674/kentucky', 'https://www.mountainproject.com/area/116720343/louisiana', 'https://www.mountainproject.com/area/105948977/maine', 'https://www.mountainproject.com/area/106029417/maryland', 'https://www.mountainproject.com/area/105908062/massachusetts', 'https://www.mountainproject.com/area/106113246/michigan', 'https://www.mountainproject.com/area/105812481/minnesota', 'https://www.mountainproject.com/area/108307056/mississippi', 'https://www.mountainproject.com/area/105899020/missouri', 'https://www.mountainproject.com/area/105907492/montana', 'https://www.mountainproject.com/area/116096758/nebraska', 'https://www.mountainproject.com/area/105708961/nevada', 'https://www.mountainproject.com/area/105872225/new-hampshire', 'https://www.mountainproject.com/area/106374428/new-jersey', 'https://www.mountainproject.com/area/105708964/new-mexico', 'https://www.mountainproject.com/area/105800424/new-york', 'https://www.mountainproject.com/area/105873282/north-carolina', 'https://www.mountainproject.com/area/106598130/north-dakota', 'https://www.mountainproject.com/area/105994953/ohio', 'https://www.mountainproject.com/area/105854466/oklahoma', 'https://www.mountainproject.com/area/105708965/oregon', 'https://www.mountainproject.com/area/105913279/pennsylvania', 'https://www.mountainproject.com/area/106842810/rhode-island', 'https://www.mountainproject.com/area/107638915/south-carolina', 'https://www.mountainproject.com/area/105708963/south-dakota', 'https://www.mountainproject.com/area/105887760/tennessee', 'https://www.mountainproject.com/area/105835804/texas', 'https://www.mountainproject.com/area/105708957/utah', 'https://www.mountainproject.com/area/105891603/vermont', 'https://www.mountainproject.com/area/105852400/virginia', 'https://www.mountainproject.com/area/105708966/washington', 'https://www.mountainproject.com/area/105855459/west-virginia', 'https://www.mountainproject.com/area/105708968/wisconsin', 'https://www.mountainproject.com/area/105708960/wyoming', 'https://www.mountainproject.com/area/105907743/international', 'https://www.mountainproject.com/area/105798164/in-progress']\n",
    "skip = ['https://www.mountainproject.com/area/105905173/alabama', 'https://www.mountainproject.com/area/105909311/alaska','https://www.mountainproject.com/area/105708962/arizona', 'https://www.mountainproject.com/area/105901027/arkansas', 'https://www.mountainproject.com/area/105708959/california', 'https://www.mountainproject.com/area/105708956/colorado', 'https://www.mountainproject.com/area/105806977/connecticut', 'https://www.mountainproject.com/area/106861605/delaware', 'https://www.mountainproject.com/area/111721391/florida', 'https://www.mountainproject.com/area/105897947/georgia', 'https://www.mountainproject.com/area/106316122/hawaii', 'https://www.mountainproject.com/area/105708958/idaho', 'https://www.mountainproject.com/area/105911816/illinois', 'https://www.mountainproject.com/area/112389571/indiana']\n",
    "for key in skip:\n",
    "  states.pop(key)\n",
    "print(states)\n",
    "last = skip[-1].split(\"/\")[-1]\n",
    "print(last)\n",
    "\n",
    "for key in states:\n",
    "  areas, ids = getAreas(key)\n",
    "  states[key]['subAreaIds'] = ids\n",
    "  states[key]['subAreaUrls'] = areas\n",
    "  subareas = []\n",
    "  print(f\"\\n\\n ------{key} ------\")\n",
    "  for area in areas:\n",
    "    getSubAreas(area, parent=key, shouldGetRoutes=True)\n",
    "  states[key]['subareas'] = subareas\n",
    "  print(f\"Subareas scraped in this state: {len(subareas)}\")\n",
    "  print(f\"Total route IDs scraped: {len(uniqueRouteIds)}\")\n",
    "\n",
    "  data = cleanDataForExport(states)\n",
    "  df_areas = pd.DataFrame(data)\n",
    "  # df_areas.to_csv(f\"/content/gdrive/'My Drive'/'Mountain Project Scrape'/areas.csv\", index=False)\n",
    "  df_areas.to_csv(f\"/content/gdrive/My Drive/Mountain Project Scrape/areas-after-{last}.csv\", index=False)\n",
    "\n",
    "  df_routes = pd.DataFrame(uniqueRouteIds)\n",
    "  df_routes.to_csv(f\"/content/gdrive/My Drive/Mountain Project Scrape/route_ids-after-{last}.csv\", index=False)\n",
    "\n",
    "  with open(f\"/content/gdrive/My Drive/Mountain Project Scrape/route_loc_ids-after-{last}.csv\", \"w\", newline='') as out:\n",
    "    csv_out = csv.writer(out)\n",
    "    csv_out.writerow(['routeId', 'locationId'])\n",
    "    for row in route_location_ids:\n",
    "      csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I52mvcnpMmCe"
   },
   "outputs": [],
   "source": [
    "def cleanDataForExport(dirty):\n",
    "  areas = []\n",
    "  for key, value in dirty.items():\n",
    "    areas.append({\n",
    "        'parent': value['parent'],\n",
    "        'title': value['title'],\n",
    "        'url': value['url'],\n",
    "        'subAreaIds': value['subAreaIds'],\n",
    "        'subAreaUrls': value['subAreaUrls'],\n",
    "        'routes': value['routes'],\n",
    "        'id': value['id']\n",
    "    })\n",
    "    areas.extend(value['subareas'])\n",
    "  return areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWiHqSoBaB3L"
   },
   "outputs": [],
   "source": [
    "# # Export Routes\n",
    "# df_routes = pd.DataFrame(uniqueRouteIds)\n",
    "# df_routes.to_csv('route_ids.csv', index=False)\n",
    "\n",
    "# # Export Areas\n",
    "# data = cleanDataForExport(states)\n",
    "# df_areas = pd.DataFrame(data)\n",
    "# df_areas.to_csv('areas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vh40IObSxcmn"
   },
   "outputs": [],
   "source": [
    "all_routes = []\n",
    "\n",
    "import csv\n",
    "route_location_ids = {}\n",
    "with open(\"/content/gdrive/My Drive/Mountain Project Scrape/route_loc_ids.csv\") as read_obj:\n",
    "  csv_dict_reader = csv.DictReader(read_obj)\n",
    "  for row in csv_dict_reader:\n",
    "    route_location_ids[int(row['routeId'])] = int(row['locationId'])\n",
    "\n",
    "def get_routes(ids, pause=5):\n",
    "  time.sleep(pause)\n",
    "  str_ids = ','.join(str(x) for x in ids)\n",
    "  params = {\n",
    "      'key': apikey,\n",
    "      'routeIds': str_ids\n",
    "  }\n",
    "  r = requests.get('https://www.mountainproject.com/data/get-routes', params=params)\n",
    "  if(r.json()['success'] == 1):\n",
    "    routes = r.json()['routes']\n",
    "    # enhance with location ID\n",
    "    for route in routes:\n",
    "      locationId = route_location_ids[route['id']]\n",
    "      route['locationId'] = locationId\n",
    "    return routes\n",
    "  else:\n",
    "    print(\"Error\")\n",
    "    print(r.json())\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2JZ-_vAKbv4"
   },
   "outputs": [],
   "source": [
    "# Get all routes\n",
    "routeIds = list(route_location_ids.keys())\n",
    "\n",
    "def divide_chunks(l, n): \n",
    "  for i in range(0, len(l), n):  \n",
    "    yield l[i:i + n]\n",
    "\n",
    "chunked = list(divide_chunks(routeIds, 200))\n",
    "i = 0\n",
    "for chunk in chunked:\n",
    "  routes = get_routes(chunk)\n",
    "  all_routes.extend(routes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+c4uRzztZJAU9f1k/3fE+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1mLZuWXK5JvQl0PfI9MznD_nYvwXeF6Le",
   "name": "Mountain Project Scraping",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
